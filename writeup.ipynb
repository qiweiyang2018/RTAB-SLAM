{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-14T07:02:21.715816Z",
     "start_time": "2019-04-14T07:02:21.700642Z"
    }
   },
   "source": [
    "# RTAB-SLAM Implementation in ROS\n",
    "\n",
    "-> Qiwei Yang April, 14, 2019 <- \n",
    "\n",
    "### Abstract\n",
    "\n",
    "Robot localization and mapping are essential in robotics. Different problems are formed according to availability of the information. However, if\n",
    "neither of them is known, this problem becomes Simultaneous Localization and Mapping (SLAM for short). There are several slam algorithms: \n",
    "RGBD-slam, RTAB-SLAM, ORB-SLAM. In this project, RTAB-SLAM, Real Time Appearance Based Mapping, is used to construct the environment map.\n",
    "  \n",
    "### Introduction\n",
    "\n",
    "Robot localization is essential to solve robot path planning / navigation tasks. Localization problem is that, a map and the robot's \n",
    "initial poses are already known to the robot. It needs to accurately estimate its poses simultaneously through measurements while moving in it. Two different algorithms work very well\n",
    "to solve localization problems, one is the (extended) kalman filter, and the other monte carlo localization. In practice, these two algorithms\n",
    "are combined to generate very accurate result. Robotics motion, IMU measurements, GPS, etc, are first feed into a kalman filter, and then monte\n",
    "carlo method is applied for further process.\n",
    "\n",
    "![localization](./images/kfandmc.png)  \n",
    "[Reference] (https://ieeexplore.ieee.org/document/4650585) \n",
    "\n",
    "On the other hand, if the map is unknown to the robot, while the initial poses are still known. The robot needs to construct the map about its environmetn \n",
    "while it is navigating in the environment, this is called mapping. After the map is constructed, path planning and navigation can be performed sequentially.\n",
    "\n",
    "\n",
    "Further more, if both the map and initial poses are unknown to the robot, the robot needs to construct the map and at the same time, estimate its\n",
    "poses, this problem is called SLAM. How can the robot achieve this? The inputs for the problem\n",
    "are measurements and control, and outputs are poses (trajectory is comprised of series of poses). \n",
    "\n",
    "![SLAM](./images/slam.png)  \n",
    "[Reference] (Udacity Robotics Course) \n",
    "\n",
    "## 2. Project Goal\n",
    "\n",
    "The main purpose of this project is to get me familiar with RTAB-SLAM package, and how to set up the environment to make it work properly.\n",
    "The difficulty of this project is mainly due to the complex configuration of different files, such as .world, urdf file, rtabmap_ros parameters, etc.\n",
    " \n",
    "\n",
    "## 3. SLAM Challenges\n",
    "\n",
    "Big challenges in SLAM are mainly due to high dimensions. The continuous parameter space composed of the robot poses and the location \n",
    "of the objects is highly dimensional. While mapping the environment and localizing itself, the robot will encounter many objects and \n",
    "have to keep track of each one of them. Thus, the number of variables will increase with time, and this makes the problem highly \n",
    "dimensional and challenging to compute the posterior.\n",
    "\n",
    "In addition, the discrete parameter space is composed out of the correspondence values, and is also highly dimensional due to the large number \n",
    "of correspondence variables. Not only that, the correspondence values increase exponentially over time since the robot will keep sensing \n",
    "the environment and relating the newly detected objects to the previously detected ones. Even if you assume known correspondence values, \n",
    "the posterior over maps is still highly dimensional.\n",
    "\n",
    "## 4. RTAB-Mapping\n",
    "\n",
    "RTAB-Map (Real-Time Appearance-Based Mapping) is a RGB-D, Stereo and Lidar Graph-Based SLAM approach based on an incremental \n",
    "appearance-based loop closure detector. The loop closure detector uses a bag-of-words approach to determinate how likely a new \n",
    "image comes from a previous location or a new location. When a loop closure hypothesis is accepted, a new constraint is added to \n",
    "the mapâ€™s graph, then a graph optimizer minimizes the errors in the map. A memory management approach is used to limit the number \n",
    "of locations used for loop closure detection and graph optimization, so that real-time constraints on large-scale environments \n",
    "are always respected. RTAB-Map can be used alone with a handheld Kinect, a stereo camera or a 3D lidar for 6DoF mapping, or on a \n",
    "robot equipped with a laser rangefinder for 3DoF mapping.\n",
    "[rtabmap](hhttp://introlab.github.io/rtabmap/)  \n",
    "\n",
    "## 5. Scene and Robot\n",
    "\n",
    "### 5.1 Scene\n",
    "\n",
    "A new scene was built by modifying the Jackal_race environment.\n",
    "\n",
    "![robot](./images/custom.png) \n",
    "\n",
    "\n",
    "### 5.2 Robot\n",
    "\n",
    "A simple robot was built and its information was shown below: \n",
    "\n",
    "![robot](./images/robot.png) \n",
    "\n",
    "![robot](./images/tf.png) \n",
    "\n",
    "### 5.3 Result\n",
    "\n",
    "![result](./images/map.png) \n",
    "\n",
    "However, if an environment that has no obvious landmarks, or all images are similar to each other. RTAB-Slam does not work well. \n",
    "As you can see below, the quality of the world map constructed is poor1.\n",
    " \n",
    "![result](./images/bad.png) \n",
    "\n",
    "## 6. SLAM Comparison\n",
    "\n",
    "![Comparison](./images/slamcompare.png)\n",
    "\n",
    "[Reference] (https://arxiv.org/abs/1707.09808) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
